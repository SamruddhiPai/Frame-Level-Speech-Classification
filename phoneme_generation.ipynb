{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46sV04HFTnFi"
   },
   "source": [
    "- Section with imports + notes on what they are\n",
    "- Section on loading data w/reference back to dataloaders\n",
    "- Include note on importing from kaggle\n",
    "- Model + dataset section w/extra notes\n",
    "    - talk about context in dataset section \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzx6BrmZTnFn"
   },
   "source": [
    "# Importing Libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6SLfMW6cTnFo"
   },
   "outputs": [],
   "source": [
    "#These libraries help to interact with the operating system and the runtime environment respectively\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#Model/Training related libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "#Dataloader libraries\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZJe5-hlTnFr"
   },
   "source": [
    "# Setting up Data\n",
    "\n",
    "To be able to use our data in training, the data must be loaded and stored in a workable form. In our case, we want to reformat our data into a pytorch tensor - which we can then store into a Dataset and Dataset Loader that can be used by our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W2CFUM-PTnFu"
   },
   "source": [
    "### 1. Load Data\n",
    "\n",
    "\n",
    "\n",
    "All homework datasets are accessible through Kaggle. Ideally, you don't want to download all the data locally onto your laptop. Instead, they can be loaded to the temporary process your notebook is working on. We will show an example here, with some tips on dataformatting. For more details, reference the Colab recitation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W_Hlvgup_wYv",
    "outputId": "f0f64b7b-523a-4834-c41e-8aef49a7c67a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
     ]
    }
   ],
   "source": [
    "#Intall Kaggle API and create kaggle directory\n",
    "!pip install kaggle\n",
    "!mkdir .kaggle\n",
    "#This data is used to login  into your Kaggle account\n",
    "import json\n",
    "token = {\"username\":\"samruddhi98\",\"key\":\"db26269bc2e5ae4d4f8456490e50b5a8\"}\n",
    "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
    "    json.dump(token, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y5Cf5ClPJl2I",
    "outputId": "86e25e28-a148-4f09-ff75-e39943ecc6e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- path is now set to: /content\n"
     ]
    }
   ],
   "source": [
    "!chmod 600 /content/.kaggle/kaggle.json\n",
    "!cp /content/.kaggle/kaggle.json /root/.kaggle/\n",
    "!kaggle config set -n path -v /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E_1H-U6KXEgl",
    "outputId": "5ed768db-a018-4d25-ac9c-948ed45d88c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mSLSs0MUjVRE",
    "outputId": "548c0a77-8308-4d9c-ad07-7662b38577e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
      "Downloading train.npy.zip to /content/competitions/idl-fall2021-hw1p2\n",
      " 99% 1.89G/1.92G [00:08<00:00, 273MB/s]\n",
      "100% 1.92G/1.92G [00:08<00:00, 238MB/s]\n",
      "Downloading sample.csv.zip to /content/competitions/idl-fall2021-hw1p2\n",
      "  0% 0.00/4.03M [00:00<?, ?B/s]\n",
      "100% 4.03M/4.03M [00:00<00:00, 133MB/s]\n",
      "Downloading dev.npy.zip to /content/competitions/idl-fall2021-hw1p2\n",
      " 97% 238M/246M [00:00<00:00, 270MB/s]\n",
      "100% 246M/246M [00:00<00:00, 267MB/s]\n",
      "Downloading test.npy.zip to /content/competitions/idl-fall2021-hw1p2\n",
      " 94% 227M/241M [00:05<00:00, 40.6MB/s]\n",
      "100% 241M/241M [00:05<00:00, 42.6MB/s]\n",
      "Downloading dev_labels.npy.zip to /content/competitions/idl-fall2021-hw1p2\n",
      "  0% 0.00/617k [00:00<?, ?B/s]\n",
      "100% 617k/617k [00:00<00:00, 86.3MB/s]\n",
      "Downloading train_labels.npy.zip to /content/competitions/idl-fall2021-hw1p2\n",
      "  0% 0.00/5.16M [00:00<?, ?B/s]\n",
      "100% 5.16M/5.16M [00:00<00:00, 84.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "#Download dataset .npz files from kaggle\n",
    "!kaggle competitions download -c idl-fall2021-hw1p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dFFS-N3lEnPz",
    "outputId": "9e613003-ffa8-4700-fea1-e727016175da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  competitions/idl-fall2021-hw1p2/train.npy.zip\n",
      "  inflating: competitions/idl-fall2021-hw1p2/train.npy  \n",
      "Archive:  competitions/idl-fall2021-hw1p2/train_labels.npy.zip\n",
      "  inflating: competitions/idl-fall2021-hw1p2/train_labels.npy  \n",
      "Archive:  competitions/idl-fall2021-hw1p2/dev.npy.zip\n",
      "  inflating: competitions/idl-fall2021-hw1p2/dev.npy  \n",
      "Archive:  competitions/idl-fall2021-hw1p2/dev_labels.npy.zip\n",
      "  inflating: competitions/idl-fall2021-hw1p2/dev_labels.npy  \n",
      "Archive:  competitions/idl-fall2021-hw1p2/test.npy.zip\n",
      "  inflating: competitions/idl-fall2021-hw1p2/test.npy  \n"
     ]
    }
   ],
   "source": [
    "!unzip -d competitions/idl-fall2021-hw1p2/ competitions/idl-fall2021-hw1p2/train.npy.zip \n",
    "!unzip -d competitions/idl-fall2021-hw1p2/ competitions/idl-fall2021-hw1p2/train_labels.npy.zip \n",
    "!unzip -d competitions/idl-fall2021-hw1p2/ competitions/idl-fall2021-hw1p2/dev.npy.zip \n",
    "!unzip -d competitions/idl-fall2021-hw1p2/ competitions/idl-fall2021-hw1p2/dev_labels.npy.zip \n",
    "!unzip -d competitions/idl-fall2021-hw1p2/ competitions/idl-fall2021-hw1p2/test.npy.zip "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_W7QsdFTnFt"
   },
   "source": [
    "### 2. Set up Dataset Class\n",
    "\n",
    "The dataset class is used to format the input/output pairs and store them as well. For more details, recall the Dataset and Dataloader recitation on how each of these features work, as well as the OOP lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "P4qbPfrXG9li"
   },
   "outputs": [],
   "source": [
    "class MLPDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data, labels, context=0):\n",
    "        self.data = data \n",
    "        self.labels = labels \n",
    "        self.length = len(self.labels)\n",
    "        self.context = context\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        x = self.data[index:index+2*self.context+1,:]\n",
    "        y = self.labels[index]\n",
    "        return x,y\n",
    "    \n",
    "    def collate_fn(batch):\n",
    "        batch_x = [x for x,y in batch]\n",
    "        batch_y = [y for x,y in batch]\n",
    "        batch_x = torch.as_tensor(batch_x)\n",
    "        batch_y = torch.as_tensor(batch_y)\n",
    "        return batch_x,batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3MaBX9f1H25w",
    "outputId": "e37dc3a2-8e03-4c46-dfc2-71d9765c6ee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14542,)\n",
      "(14542,)\n",
      "(2683,)\n",
      "(2683,)\n",
      "(2600,)\n"
     ]
    }
   ],
   "source": [
    "### Load the Data\n",
    "x_train = np.load('competitions/idl-fall2021-hw1p2/train.npy',allow_pickle=True) # Data file name\n",
    "labels_train = np.load('competitions/idl-fall2021-hw1p2/train_labels.npy',allow_pickle=True) # Label file name\n",
    "x_val = np.load('competitions/idl-fall2021-hw1p2/dev.npy',allow_pickle=True) # Data file name\n",
    "labels_val = np.load('competitions/idl-fall2021-hw1p2/dev_labels.npy',allow_pickle=True) # Label file name \n",
    "x_test = np.load('competitions/idl-fall2021-hw1p2/test.npy',allow_pickle=True) # Data file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vTld29O363v5",
    "outputId": "0d5dff86-5e5d-4bc2-afe6-47fa4b92c166"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1910062, 40) (1910012,)\n"
     ]
    }
   ],
   "source": [
    "context = 25\n",
    "\n",
    "## Concatenating and padding the data\n",
    "# Training\n",
    "x_train = np.concatenate(x_train,axis=0)\n",
    "x_train = np.pad(x_train, ((context, context), (0, 0)), 'constant', constant_values=0)\n",
    "labels_train = np.concatenate(labels_train,axis=0)\n",
    "# Validation \n",
    "x_val = np.concatenate(x_val,axis=0)\n",
    "x_val = np.pad(x_val, ((context, context), (0, 0)), 'constant', constant_values=0)\n",
    "labels_val = np.concatenate(labels_val,axis=0)\n",
    "# Testing\n",
    "x_test = np.concatenate(x_test,axis=0)\n",
    "labels_test = np.random.randint(71,size=x_test.shape[0])\n",
    "x_test = np.pad(x_test, ((context, context), (0, 0)), 'constant', constant_values=0)\n",
    "print(x_test.shape,labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fj-b3rzgTnFw",
    "outputId": "ea852060-4b28-4c73-f5ea-7e94257cf59a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is  cuda:0\n"
     ]
    }
   ],
   "source": [
    "## Dataloaders\n",
    "batch_size = 128\n",
    "test_batch_size = 4\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device is ',device)\n",
    "\n",
    "# Training dataloader\n",
    "train_data = MLPDataset(x_train, labels_train, context=context)\n",
    "train_args = dict(shuffle = True, batch_size = batch_size, num_workers=4, collate_fn=MLPDataset.collate_fn)\n",
    "train_loader = DataLoader(train_data, **train_args)\n",
    "\n",
    "# Validation dataloader\n",
    "val_data = MLPDataset(x_val, labels_val, context=context)\n",
    "val_args = dict(shuffle = False, batch_size = batch_size, num_workers=4, collate_fn=MLPDataset.collate_fn)\n",
    "val_loader = DataLoader(val_data, **val_args)\n",
    "\n",
    "# Testing dataloader\n",
    "test_data = MLPDataset(x_test, labels_test, context=context)\n",
    "test_args = dict(shuffle = False, batch_size = test_batch_size, num_workers=4, collate_fn=MLPDataset.collate_fn)\n",
    "test_loader = DataLoader(test_data, **test_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wVJwuYbtTnFw"
   },
   "outputs": [],
   "source": [
    "## Model Architecture definition\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    # define model elements\n",
    "    def __init__(self, size):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # Sequential model definition: Input -> Linear -> ReLU -> Linear -> Softmax -> Output\n",
    "        \n",
    "        self.model = nn.Sequential(nn.Linear(size[0], size[1]), \n",
    "                                   nn.BatchNorm1d(size[1]),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Dropout(0.25,inplace=False),\n",
    "                                   nn.Linear(size[1], size[2]),\n",
    "                                   nn.BatchNorm1d(size[2]),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Dropout(0.25,inplace=False),\n",
    "                                   nn.Linear(size[2], size[3]), \n",
    "                                   nn.BatchNorm1d(size[3]),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Dropout(0.25,inplace=False),\n",
    "                                   nn.Linear(size[3], size[4]),\n",
    "                                   nn.BatchNorm1d(size[4]),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(size[4], size[5]),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(size[5], size[6])\n",
    "                                   )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Model forward pass\n",
    "        self.x = self.model(x)\n",
    "        return self.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U865X7LWTnFw",
    "outputId": "f63ffa0d-2fd0-41ea-db3f-0e520a946811"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=2040, out_features=4096, bias=True)\n",
      "    (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.25, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "    (5): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.25, inplace=False)\n",
      "    (8): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "    (9): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.25, inplace=False)\n",
      "    (12): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (13): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU()\n",
      "    (15): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (16): ReLU()\n",
      "    (17): Linear(in_features=512, out_features=71, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "input_size = (2*context+1)*40\n",
    "model = MLP([input_size, 4096, 2048, 2048, 1024, 512, 71])\n",
    "model.to(device)\n",
    "# Define Criterion/ Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define Adam Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "# exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, \n",
    "#                                              step_size=7, gamma=0.1)\n",
    "rlr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=2, threshold=0.01, min_lr=0.0001)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9Lw80z9KTnFx"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "from tqdm import tqdm\n",
    "def train_model(train_loader, model,batch_size):\n",
    "    training_loss = 0\n",
    "    \n",
    "    # Set model in 'Training mode'\n",
    "    model.train()\n",
    "    \n",
    "    # enumerate mini batches\n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "        for inputs, targets in tepoch:\n",
    "            if (inputs.size()[0]==batch_size):\n",
    "            # clear the gradients\n",
    "                optimizer.zero_grad()\n",
    "                inputs = inputs.type(torch.FloatTensor).to(device)\n",
    "                targets = targets.type(torch.LongTensor).to(device)\n",
    "                # compute the model output\n",
    "                out = model(inputs.view(batch_size,-1))\n",
    "                # calculate loss\n",
    "                loss = criterion(out,targets)\n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                # Update model weights\n",
    "                optimizer.step()\n",
    "\n",
    "                training_loss += loss.item()\n",
    "        training_loss /= len(train_loader)\n",
    "        return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "73l8p3IWTnFz"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "def evaluate_model(val_loader, model,batch_size):\n",
    "    # with torch.no_grad():\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    # Set model in validation mode\n",
    "    model.eval()\n",
    "    \n",
    "    with tqdm(val_loader, unit=\"batch\") as tepoch:\n",
    "        for inputs, targets in tepoch:    \n",
    "        # evaluate the model on the validation set \n",
    "            if (inputs.size()[0]==batch_size):\n",
    "                inputs = inputs.type(torch.FloatTensor).to(device)\n",
    "                targets = targets.type(torch.LongTensor).to(device)\n",
    "                out = model(inputs.view(batch_size,-1))\n",
    "                # Calculate validation loss\n",
    "                loss = criterion(out,targets)\n",
    "                # retrieve numpy array\n",
    "                out = out.cpu().detach().numpy()\n",
    "                actual = targets.cpu().numpy()\n",
    "                # convert to class labels\n",
    "                out = np.argmax(out,axis=1)\n",
    "                predictions.append(out)\n",
    "                actuals.append(actual)\n",
    "        predictions, actuals = np.asarray(predictions).flatten(), np.asarray(actuals).flatten()\n",
    "        # print(predictions.shape,actuals.shape)\n",
    "        acc = accuracy_score(actuals, predictions)\n",
    "        return acc, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "W4tuzmPJ3_NN"
   },
   "outputs": [],
   "source": [
    "# Test the model\n",
    "\n",
    "def predict_model(test_loader, model,batch_size):\n",
    "    predictions = []\n",
    "    model.eval()\n",
    "    \n",
    "    with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
    "        for inputs, targets in tepoch:\n",
    "            if (inputs.size()[0]==batch_size):\n",
    "                inputs = inputs.type(torch.FloatTensor).to(device)\n",
    "                targets = targets.type(torch.LongTensor).to(device)\n",
    "                out = model(inputs.view(batch_size,-1))\n",
    "                out = out.cpu().detach().numpy()\n",
    "                out = np.argmax(out,axis=1)\n",
    "                predictions.append(out)\n",
    "                \n",
    "        predictions = np.asarray(predictions).flatten()\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OOM60IGtTnF0",
    "outputId": "68b83c3f-97c6-4955-8537-fe1e7df94bf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144399/144399 [53:36<00:00, 44.89batch/s]\n",
      "100%|██████████| 15123/15123 [04:49<00:00, 52.17batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, lr 0.0005\n",
      "Epoch: 11, Training loss: 0.541172926608208, Validation loss:3.2272121906280518, Validation accuracy:77.87195394127761%\n",
      "Starting epoch  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2302/144399 [00:52<50:45, 46.66batch/s]"
     ]
    }
   ],
   "source": [
    "# Define number of epochs\n",
    "\n",
    "if __name__=='__main__':\n",
    "    \n",
    "    epochs = 20\n",
    "    for epoch in range(11,epochs):\n",
    "        print('Starting epoch ',epoch)\n",
    "        # Train\n",
    "        training_loss = train_model(train_loader, model, batch_size)\n",
    "        # Validation\n",
    "        val_acc, val_loss = evaluate_model(val_loader, model, batch_size)\n",
    "        rlr_scheduler.step(val_acc)\n",
    "\n",
    "        PATH = 'model-4_epoch%d_val_acc-%0.4f.pt'%(epoch,val_acc)\n",
    "\n",
    "        # Save\n",
    "        torch.save({\n",
    "            'epoch': epochs,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler': rlr_scheduler.state_dict(),\n",
    "            'loss': training_loss,\n",
    "            'val_accuracy': val_acc,\n",
    "            'val_loss': val_loss\n",
    "            }, PATH)\n",
    "        \n",
    "        print('Epoch {}, lr {}'.format(epoch, optimizer.param_groups[0]['lr']))\n",
    "\n",
    "        # Print log of accuracy and loss\n",
    "        print(\"Epoch: \"+str(epoch)+\", Training loss: \"+str(training_loss)+\", Validation loss:\"+str(val_loss)+\n",
    "          \", Validation accuracy:\"+str(val_acc*100)+\"%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bGpLmIta0ciu",
    "outputId": "ab1188fe-c83e-4afa-e0da-6041747c7873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading drive/MyDrive/IDL-HW1P2/model-4_epoch10_val_acc-0.7787.pt model \n"
     ]
    }
   ],
   "source": [
    "# Loading the model for predicting labels on test data\n",
    "epoch = 11 # load the best model\n",
    "val_acc = 0.7787 # the corresponding accuracy\n",
    "PATH = 'model-4_epoch%d_val_acc-%0.4f.pt'%(epoch,val_acc)\n",
    "print('Loading %s model '%(PATH))\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "rlr_scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "epochs = checkpoint['epoch']\n",
    "training_loss = checkpoint['loss']\n",
    "val_acc = checkpoint['val_accuracy']\n",
    "val_loss = checkpoint['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KIVpbV95u-PK",
    "outputId": "85510fd8-1d29-4c67-d0b6-cc9d5efc898b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477503/477503 [15:34<00:00, 511.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of predicted data is  (1910012,)\n"
     ]
    }
   ],
   "source": [
    "# Predicting data\n",
    "preds = predict_model(test_loader, model, batch_size=test_batch_size)\n",
    "print('Shape of predicted data is ',preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WM_CgwgmvUHd",
    "outputId": "d68b1b44-90e7-4a7e-ef4f-e95beaf5cb9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id            id  label\n",
      "0              0      0\n",
      "1              1      0\n",
      "2              2      0\n",
      "3              3      0\n",
      "4              4      0\n",
      "...          ...    ...\n",
      "1910007  1910007      0\n",
      "1910008  1910008      0\n",
      "1910009  1910009      0\n",
      "1910010  1910010      0\n",
      "1910011  1910011      0\n",
      "\n",
      "[1910012 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Saving in csv format\n",
    "import pandas as pd\n",
    "filename = 'drive/MyDrive/IDL-HW1P2/submissions_2.csv'\n",
    "index = np.arange(0,preds.shape[0])\n",
    "data = {'id':list(index),\n",
    "        'label':list(preds)}\n",
    "pred_df = pd.DataFrame(data)\n",
    "pred_df = pred_df.rename_axis('id',axis=1)\n",
    "print(pred_df)\n",
    "pred_df.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YZrDA-349yO_",
    "outputId": "87ec02d8-4cd5-4adf-9973-73e9e8afb993"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
      "100% 18.5M/18.5M [00:08<00:00, 2.21MB/s]\n",
      "Successfully submitted to IDL-Fall21-HW1P2"
     ]
    }
   ],
   "source": [
    "# Submitting predictions to kaggle\n",
    "!kaggle competitions submit -c idl-fall2021-hw1p2 -f {filename} -m \"Model-1 submission\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "HW1P2_solution.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "627c243d0bd314a2fea4506ebd8ca522b68dafb0e7468df7979a81b3dbd048c4"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
